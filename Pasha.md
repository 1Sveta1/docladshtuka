Моя часть текста, буду писать в мд, общий док будет как покладено)

#Вступаем в новый "Раздел"
	
Как можно было заметить ранее - lip sync - сложный и долгий ручной процесс ранее, а если над ним не работать, то качество выходящего материала будет не самое высокое, что будет бить по погружению в произведение или работу.
Поэтому возникла потребность в качественном lip sync-е с минимальными затратами для создателя, и при этом - высоким качеством материала.
Как и во многих других отраслях логичным становиться использование нейронных сетей для решения таких сложных заданий.
Так для решения проблем переводов может использоваться Wav2Lip подобная нейронная сеть, что анализирует как аудио, так и видео сингнал находит лицо говорящего человека и анализируя звук находит произносимые звуки, что имеют ярковыраженный тип постановки рта.
Как можно заметить здесь, это можно использовать не только для переовда материалов на разные языки, но и для простой синхронизации звука с видео, если аудио сигнал имеет непостоянные высокие задержки. Или и вовсе - сигнал прерываеться, так как сеть на основе предыдущих кадров способна построить видео используя один лишь звук.
Таким образом, имея лицо, с распознанным ртом и расставленными моментами с возможными вариациями звуков, нейронная сеть принимает решение, на какой звук выбрать какой рот, что генерируеться во время анализа видео потока.
Как можно понять, такая нейронная сеть применима только к тем работам, где говорящее лицо - человек, или человеко-подобное существо с достаточно реалистичным видом.
Однако не всегда нужно переводить какое-то произведение или выступление, например, если во время обучения появиться необходимость показать историческую личность с её цитатой ранее бы пришлось рисовать лицо, или и вовсе - прилепить рисованые выбивающиеся губы к портрету личности, что портит общее ощущение важности цитаты и придаёт комичности.
С использованием LipGAN можно решить эту проблему, и ещё несколько других по пути. Так нейронная сеть LipGAN анализирует видео поток, который может быть и вовсе - статичной картинкой и звукуовую дорожку и на выходе даёт реалистичное видео с синхронизироваными движениями рта и звука. Так например можно "Оживить" Елизавету I и вручить ей её цитату на уроках истории.
Эта же технология по заявлению авторов позволит разработчикам игр создавать правдоподобные анимации лица для персонажей своих игр с множеством локализаций.
Однако, если вы автор собственных анимаций или стример что не хочет показывать своё лицо, то вам может помочь CharacterLipSync, эта нейронная сеть использует заранее нарисованные эмоции и звуки для создания видео потока в реальном времени. Может использоваться как с трекингом по лицу, так и без него. Как и во всех нейронных сетях выше - производиться анализ аудио-дорожки, однако видео сигнал здесь полностью генерируем без использования трекинга (что часто делаеться во время стримов), таким образом нейронная сеть не только анализирует аудио и подбирает необходимый сейчас рот для персонажа, но ещё и создаёт переход между каждой сменой, что вручную делать намного дольше, даже если бы все рты были расставлены сразу.
Таким образом эта нейронная сеть решает сразу несколько проблем, если её комбинировать с другими - проблему аниматоров, которым достаточно будет нарисовать базовые рты и предоставить нейронной сети аудиопоток с озвучкой персонажа, а также проблемы стримеров-анонимов, которым ранее требовалось дорогостоящее оборудование для распознавания мимики на лице и движения тела, теперь же, с использованием комбинации нейронных сетей можно делать такой видео поток в реальном времени пользуясь одной лишь веб-камерой и микрофоном.